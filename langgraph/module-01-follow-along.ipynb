{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 01: LangGraph Fundamentals - Follow Along\n\n",
                "**Purpose:** Run all examples from the theory document  \n",
                "**How to use:** Execute each cell in order to see LangGraph in action  \n",
                "**After this:** Move to `module-01-practice.ipynb` for exercises\n\n",
                "---\n\n",
                "This notebook contains all working code examples from Module 01 theory document.\n",
                "Run each cell and observe the outputs to understand how LangGraph works.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "%pip install -q -U langgraph langchain langchain-openai python-dotenv\n\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n\n",
                "print('✅ Environment ready!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 1: Understanding State\n\n",
                "State is the shared data structure that flows through your graph.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import TypedDict, Annotated\n",
                "from langgraph.graph.message import add_messages\n\n",
                "# Define a state schema\n",
                "class SimpleState(TypedDict):\n",
                "    messages: Annotated[list, add_messages]  # Messages with special reducer\n",
                "    user_name: str\n\n",
                "# Example state\n",
                "example_state = {\n",
                "    'messages': [],\n",
                "    'user_name': 'Alice'\n",
                "}\n\n",
                "print(f\"State schema defined: {SimpleState.__annotations__}\")\n",
                "print(f\"Example state: {example_state}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 2: Creating Nodes\n\n",
                "Nodes are functions that process state and return updates.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple node example\n",
                "def my_node(state: SimpleState) -> SimpleState:\n",
                "    \"\"\"A node that processes state.\"\"\"\n",
                "    result = f\"Hello, {state['user_name']}!\"\n",
                "    return {\"user_name\": state['user_name'].upper()}  # Return update\n\n",
                "# Test the node\n",
                "test_state = {'messages': [], 'user_name': 'alice'}\n",
                "update = my_node(test_state)\n",
                "print(f\"Input: {test_state}\")\n",
                "print(f\"Update returned: {update}\")\n",
                "print(f\"Note: Node returns ONLY updates, not full state\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 3: Building Your First Graph\n\n",
                "This is the complete chatbot example from the theory document.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langgraph.graph import StateGraph, START, END\n",
                "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n\n",
                "# State schema for chatbot\n",
                "class ChatState(TypedDict):\n",
                "    messages: Annotated[list, add_messages]\n",
                "    user_name: str\n\n",
                "# Node 1: Extract user name\n",
                "def extract_name_node(state: ChatState) -> ChatState:\n",
                "    \"\"\"Extract user name from first message if not already known.\"\"\"\n",
                "    if state.get('user_name'):\n",
                "        return {}  # No update needed\n",
                "    \n",
                "    first_message = state['messages'][0].content if state['messages'] else \"\"\n",
                "    if \"my name is\" in first_message.lower():\n",
                "        name = first_message.lower().split(\"my name is\")[1].strip().split()[0]\n",
                "        return {\"user_name\": name.capitalize()}\n",
                "    \n",
                "    return {}\n\n",
                "# Node 2: Chatbot (simplified - no actual LLM call)\n",
                "def chatbot_node(state: ChatState) -> ChatState:\n",
                "    \"\"\"Simulate chatbot response.\"\"\"\n",
                "    user_name = state.get('user_name', 'there')\n",
                "    response = AIMessage(content=f\"Hello {user_name}! How can I help you today?\")\n",
                "    return {\"messages\": [response]}\n\n",
                "# Build the graph\n",
                "workflow = StateGraph(ChatState)\n",
                "workflow.add_node(\"extract_name\", extract_name_node)\n",
                "workflow.add_node(\"chatbot\", chatbot_node)\n\n",
                "# Define edges\n",
                "workflow.add_edge(START, \"extract_name\")\n",
                "workflow.add_edge(\"extract_name\", \"chatbot\")\n",
                "workflow.add_edge(\"chatbot\", END)\n\n",
                "# Compile\n",
                "app = workflow.compile()\n\n",
                "print(\"✅ Graph built successfully!\")\n",
                "print(f\"Nodes: {list(app.get_graph().nodes.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 4: Running the Graph\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# First interaction\n",
                "initial_state = {\n",
                "    \"messages\": [HumanMessage(content=\"Hi, my name is Alice\")],\n",
                "    \"user_name\": \"\"\n",
                "}\n\n",
                "result = app.invoke(initial_state)\n",
                "print(\"First interaction:\")\n",
                "print(f\"  User said: {result['messages'][0].content}\")\n",
                "print(f\"  Bot replied: {result['messages'][-1].content}\")\n",
                "print(f\"  User name extracted: {result['user_name']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Follow-up (the graph remembers the name)\n",
                "follow_up_state = {\n",
                "    \"messages\": result['messages'] + [HumanMessage(content=\"What's my name?\")],\n",
                "    \"user_name\": result['user_name']\n",
                "}\n\n",
                "result2 = app.invoke(follow_up_state)\n",
                "print(\"\\nFollow-up interaction:\")\n",
                "print(f\"  User asked: {follow_up_state['messages'][-1].content}\")\n",
                "print(f\"  Bot knows: {result2['user_name']}\")\n",
                "print(f\"  ✅ State persisted across invocations!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 5: Conditional Routing\n\n",
                "Demonstrate dynamic routing based on state.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class RouterState(TypedDict):\n",
                "    score: float\n",
                "    path: str\n",
                "    result: str\n\n",
                "def classifier(state: RouterState):\n",
                "    \"\"\"Classify based on score.\"\"\"\n",
                "    return {'score': state.get('score', 0.5)}\n\n",
                "def high_confidence_handler(state: RouterState):\n",
                "    return {'result': f\"High confidence path (score: {state['score']})\"}\n\n",
                "def low_confidence_handler(state: RouterState):\n",
                "    return {'result': f\"Low confidence path (score: {state['score']})\"}\n\n",
                "# Router function\n",
                "def route_logic(state: RouterState) -> str:\n",
                "    if state['score'] > 0.8:\n",
                "        return \"high_confidence\"\n",
                "    return \"low_confidence\"\n\n",
                "# Build graph with conditional edges\n",
                "workflow = StateGraph(RouterState)\n",
                "workflow.add_node(\"classifier\", classifier)\n",
                "workflow.add_node(\"high_confidence\", high_confidence_handler)\n",
                "workflow.add_node(\"low_confidence\", low_confidence_handler)\n\n",
                "workflow.add_edge(START, \"classifier\")\n",
                "workflow.add_conditional_edges(\n",
                "    \"classifier\",\n",
                "    route_logic,\n",
                "    {\"high_confidence\": \"high_confidence\", \"low_confidence\": \"low_confidence\"}\n",
                ")\n",
                "workflow.add_edge(\"high_confidence\", END)\n",
                "workflow.add_edge(\"low_confidence\", END)\n\n",
                "router_app = workflow.compile()\n\n",
                "# Test with different scores\n",
                "for score in [0.9, 0.5]:\n",
                "    result = router_app.invoke({'score': score, 'path': '', 'result': ''})\n",
                "    print(f\"Score {score}: {result['result']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 6: Using Reducers\n\n",
                "Custom reducers define how state updates are merged.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom reducer example\n",
                "def accumulate_scores(existing: list, new: list) -> list:\n",
                "    \"\"\"Accumulate scores instead of replacing.\"\"\"\n",
                "    return existing + new\n\n",
                "class ScoreState(TypedDict):\n",
                "    scores: Annotated[list, accumulate_scores]\n\n",
                "def score_node_1(state: ScoreState):\n",
                "    return {\"scores\": [0.7, 0.8]}\n\n",
                "def score_node_2(state: ScoreState):\n",
                "    return {\"scores\": [0.9]}  # Will be appended, not replaced\n\n",
                "# Build graph\n",
                "workflow = StateGraph(ScoreState)\n",
                "workflow.add_node(\"node1\", score_node_1)\n",
                "workflow.add_node(\"node2\", score_node_2)\n",
                "workflow.add_edge(START, \"node1\")\n",
                "workflow.add_edge(\"node1\", \"node2\")\n",
                "workflow.add_edge(\"node2\", END)\n\n",
                "score_app = workflow.compile()\n",
                "result = score_app.invoke({'scores': []})\n\n",
                "print(f\"Scores accumulated: {result['scores']}\")\n",
                "print(f\"Without reducer, only [0.9] would remain!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 7: Streaming Execution\n\n",
                "See intermediate results as the graph executes.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class StreamState(TypedDict):\n",
                "    count: int\n\n",
                "def step1(state: StreamState):\n",
                "    return {'count': state.get('count', 0) + 1}\n\n",
                "def step2(state: StreamState):\n",
                "    return {'count': state['count'] + 1}\n\n",
                "def step3(state: StreamState):\n",
                "    return {'count': state['count'] + 1}\n\n",
                "workflow = StateGraph(StreamState)\n",
                "workflow.add_node(\"step1\", step1)\n",
                "workflow.add_node(\"step2\", step2)\n",
                "workflow.add_node(\"step3\", step3)\n",
                "workflow.add_edge(START, \"step1\")\n",
                "workflow.add_edge(\"step1\", \"step2\")\n",
                "workflow.add_edge(\"step2\", \"step3\")\n",
                "workflow.add_edge(\"step3\", END)\n\n",
                "stream_app = workflow.compile()\n\n",
                "print(\"Regular invoke (blocking):\")\n",
                "result = stream_app.invoke({'count': 0})\n",
                "print(f\"  Final count: {result['count']}\")\n\n",
                "print(\"\\nStreaming (see each step):\")\n",
                "for i, chunk in enumerate(stream_app.stream({'count': 0})):\n",
                "    print(f\"  Step {i+1}: {chunk}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 8: Error Handling Pattern\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ErrorState(TypedDict):\n",
                "    value: int\n",
                "    status: str\n",
                "    error: str\n\n",
                "def risky_operation(state: ErrorState):\n",
                "    \"\"\"Operation that might fail.\"\"\"\n",
                "    try:\n",
                "        if state['value'] < 0:\n",
                "            raise ValueError(\"Negative values not allowed\")\n",
                "        result = 100 / state['value']  # Division by zero possible\n",
                "        return {\"status\": \"success\", \"value\": int(result)}\n",
                "    except Exception as e:\n",
                "        return {\"status\": \"error\", \"error\": str(e)}\n\n",
                "def route_on_status(state: ErrorState) -> str:\n",
                "    return \"handle_error\" if state['status'] == \"error\" else \"success\"\n\n",
                "def handle_error(state: ErrorState):\n",
                "    return {\"value\": 0, \"error\": f\"Handled: {state.get('error', 'unknown')}\"}\n\n",
                "def handle_success(state: ErrorState):\n",
                "    return {\"status\": \"completed\"}\n\n",
                "# Build graph\n",
                "workflow = StateGraph(ErrorState)\n",
                "workflow.add_node(\"risky\", risky_operation)\n",
                "workflow.add_node(\"handle_error\", handle_error)\n",
                "workflow.add_node(\"success\", handle_success)\n\n",
                "workflow.add_edge(START, \"risky\")\n",
                "workflow.add_conditional_edges(\n",
                "    \"risky\",\n",
                "    route_on_status,\n",
                "    {\"handle_error\": \"handle_error\", \"success\": \"success\"}\n",
                ")\n",
                "workflow.add_edge(\"handle_error\", END)\n",
                "workflow.add_edge(\"success\", END)\n\n",
                "error_app = workflow.compile()\n\n",
                "# Test success case\n",
                "result = error_app.invoke({'value': 10, 'status': '', 'error': ''})\n",
                "print(f\"Success case (value=10): status={result['status']}\")\n\n",
                "# Test error case\n",
                "result = error_app.invoke({'value': 0, 'status': '', 'error': ''})\n",
                "print(f\"Error case (value=0): {result['error']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n\n",
                "You've seen:\n",
                "- ✅ State schemas with TypedDict\n",
                "- ✅ Node functions that return updates\n",
                "- ✅ Building graphs with StateGraph\n",
                "- ✅ START and END constants\n",
                "- ✅ Normal and conditional edges\n",
                "- ✅ Custom reducers\n",
                "- ✅ Streaming execution\n",
                "- ✅ Error handling patterns\n\n",
                "**Next Steps:**\n",
                "1. Review the theory document for detailed explanations\n",
                "2. Try `module-01-practice.ipynb` for hands-on exercises\n",
                "3. Build your own graphs!\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}