{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 07: Advanced Patterns & Optimization - Practice Notebook\n\n",
        "**Level:** Expert  \n",
        "**Duration:** 4-5 hours  \n",
        "**Updated:** December 2025 - Production patterns\n\n",
        "## Learning Objectives\n\n",
        "Expert optimization techniques:\n",
        "- âœ… Circuit breakers for resilience\n",
        "- âœ… Caching strategies\n",
        "- âœ… Performance profiling\n",
        "- âœ… Cost optimization\n",
        "- âœ… Advanced error handling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "%pip install -q -U langgraph pybreaker redis python-dotenv\n\n",
        "from pybreaker import CircuitBreaker\n",
        "import redis\n",
        "import time\n\n",
        "print('âœ… Optimization tools ready!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n---\n\n## Exercise 1: Circuit Breakers ðŸŽ¯\n\n",
        "**Objective:** Prevent cascade failures with circuit breakers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1: Circuit breaker pattern\n\n",
        "breaker = CircuitBreaker(fail_max=3, timeout_duration=60)\n\n",
        "@breaker\n",
        "def call_external_api():\n",
        "    \"\"\"External API call protected by circuit breaker.\"\"\"\n",
        "    # Simulate API failure\n",
        "    import random\n",
        "    if random.random() < 0.7:  # 70% failure rate\n",
        "        raise Exception('API Error')\n",
        "    return {'status': 'success'}\n\n",
        "# Test circuit breaker\n",
        "for i in range(10):\n",
        "    try:\n",
        "        result = call_external_api()\n",
        "        print(f'Request {i+1}: âœ… Success')\n",
        "    except Exception as e:\n",
        "        print(f'Request {i+1}: âŒ {e}')\n",
        "    time.sleep(0.1)\n\n",
        "print(f'\\nCircuit state: {breaker.current_state}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n---\n\n## Exercise 2: Redis Caching ðŸŽ¯\n\n",
        "**Objective:** Reduce costs with intelligent caching.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 2: LLM response caching\n\n",
        "import json\n",
        "import hashlib\n\n",
        "# In production, connect to real Redis\n",
        "# redis_client = redis.Redis(host='localhost', port=6379, db=0)\n",
        "# For demo, use dict\n",
        "cache = {}\n\n",
        "def cached_llm_call(prompt: str) -> str:\n",
        "    # Create cache key\n",
        "    cache_key = f'llm:{hashlib.md5(prompt.encode()).hexdigest()}'\n",
        "    \n",
        "    # Check cache\n",
        "    if cache_key in cache:\n",
        "        print(f'âœ… Cache HIT for: {prompt[:30]}...')\n",
        "        return cache[cache_key]\n",
        "    \n",
        "    # Simulate LLM call\n",
        "    print(f' ðŸ’° Cache MISS - calling LLM for: {prompt[:30]}...')\n",
        "    time.sleep(0.5)  # Simulate latency\n",
        "    result = f'Response to: {prompt}'\n",
        "    \n",
        "    #  Cache result (24hr TTL in production)\n",
        "    cache[cache_key] = result\n",
        "    \n",
        "    return result\n\n",
        "# Test caching\n",
        "prompts = [\n",
        "    'What is LangGraph?',\n",
        "    'Explain agents', \n",
        "    'What is LangGraph?',  # Duplicate - should hit cache\n",
        "    'Explain agents'        # Duplicate - should hit cache\n",
        "]\n\n",
        "for prompt in prompts:\n",
        "    result = cached_llm_call(prompt)\n\n",
        "print(f'\\nðŸ“Š Cache stats: {len(cache)} entries')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n---\n\n## Exercise 3: Performance Profiling ðŸŽ¯\n\n",
        "**Objective:** Identify and fix performance bottlenecks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 3: Profile agent performance\n\n",
        "import cProfile\n",
        "import pstats\n",
        "from io import StringIO\n\n",
        "def slow_function():\n",
        "    total = 0\n",
        "    for i in range(1000000):\n",
        "        total += i\n",
        "    return total\n\n",
        "def fast_function():\n",
        "    return sum(range(1000000))\n\n",
        "# Profile both\n",
        "profiler = cProfile.Profile()\n",
        "profiler.enable()\n\n",
        "slow_result = slow_function()\n",
        "fast_result = fast_function()\n\n",
        "profiler.disable()\n\n",
        "# Print stats\n",
        "s = StringIO()\n",
        "ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n",
        "ps.print_stats(10)\n",
        "print(s.getvalue())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n---\n\n## Exercise 4: Cost Optimization ðŸŽ¯\n\n",
        "**Objective:** Track and reduce LLM costs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 4: Token usage tracking\n\n",
        "class CostTracker:\n",
        "    def __init__(self):\n",
        "        self.total_tokens = 0\n",
        "        self.total_cost = 0\n",
        "        # GPT-4 pricing (example)\n",
        "        self.cost_per_1k_tokens = 0.03\n",
        "    \n",
        "    def track(self, prompt_tokens: int, completion_tokens: int):\n",
        "        tokens = prompt_tokens + completion_tokens\n",
        "        cost = (tokens / 1000) * self.cost_per_1k_tokens\n",
        "        \n",
        "        self.total_tokens += tokens\n",
        "        self.total_cost += cost\n",
        "        \n",
        "        return cost\n",
        "    \n",
        "    def report(self):\n",
        "        print(f'ðŸ“Š Cost Report:')\n",
        "        print(f'  Total tokens: {self.total_tokens:,}')\n",
        "        print(f'  Total cost: ${self.total_cost:.4f}')\n",
        "        print(f'  Avg cost/request: ${self.total_cost/max(1, self.requests):.4f}')\n\n",
        "tracker = CostTracker()\n\n",
        "# Simulate requests\n",
        "requests = [\n",
        "    {'prompt': 500, 'completion': 200},\n",
        "    {'prompt': 300, 'completion': 150},\n",
        "    {'prompt': 1000, 'completion': 500}\n",
        "]\n\n",
        "for req in requests:\n",
        "    cost = tracker.track(req['prompt'], req['completion'])\n",
        "    print(f'Request cost: ${cost:.4f}')\n\n",
        "tracker.report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n---\n\n## Exercise 5: Advanced Error Handling ðŸŽ¯\n\n",
        "**Objective:** Implement graceful degradation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 5: Retry with exponential backoff\n\n",
        "import random\n\n",
        "def exponential_backoff_retry(func, max_retries=3):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            return func()\n",
        "        except Exception as e:\n",
        "            if attempt == max_retries - 1:\n",
        "                raise\n",
        "            \n",
        "            wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
        "            print(f'Attempt {attempt+1} failed: {e}. Retrying in {wait_time:.2f}s...')\n",
        "            time.sleep(wait_time)\n\n",
        "def unreliable_function():\n",
        "    if random.random() < 0.7:\n",
        "        raise Exception('Temporary error')\n",
        "    return 'Success!'\n\n",
        "# Test retry logic\n",
        "try:\n",
        "    result = exponential_backoff_retry(unreliable_function)\n",
        "    print(f'âœ… {result}')\n",
        "except Exception as e:\n",
        "    print(f'âŒ Final failure: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n---\n\n## ðŸ“š Summary\n\n",
        "Advanced optimization skills:\n",
        "- âœ… Circuit breakers\n",
        "- âœ… Intelligent caching\n",
        "- âœ… Performance profiling\n",
        "- âœ… Cost tracking\n",
        "- âœ… Exponential backoff\n\n",
        "**Next:** Module 08 - Multi-Agent Systems! ðŸš€\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}