{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 07: Advanced Patterns & Optimization - Follow Along\n\n",
                "**Key Topics:** Circuit breakers, Caching, Profiling, Cost optimization\n\n",
                "Run advanced optimization examples.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install -q -U pybreaker\n\n",
                "from pybreaker import CircuitBreaker\n",
                "import time\n",
                "import hashlib\n\n",
                "print('âœ… Optimization tools ready!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 1: Circuit Breaker Pattern\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prevent cascade failures\n",
                "breaker = CircuitBreaker(fail_max=3, timeout_duration=60)\n\n",
                "@breaker\n",
                "def call_external_api():\n",
                "    \"\"\"External API protected by circuit breaker.\"\"\"\n",
                "    import random\n",
                "    if random.random() < 0.7:  # 70% failure rate\n",
                "        raise Exception('API Error')\n",
                "    return {'status': 'success'}\n\n",
                "# Test\n",
                "print(\"Testing circuit breaker:\")\n",
                "for i in range(10):\n",
                "    try:\n",
                "        result = call_external_api()\n",
                "        print(f\"Request {i+1}: âœ… Success\")\n",
                "    except Exception as e:\n",
                "        print(f\"Request {i+1}: âŒ {e}\")\n",
                "    time.sleep(0.1)\n\n",
                "print(f\"\\nCircuit state: {breaker.current_state}\")\n",
                "print('âœ… Circuit opens after 3 failures!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 2: Response Caching\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LLM response caching\n",
                "cache = {}  # In production: use Redis\n\n",
                "def cached_llm_call(prompt: str) -> str:\n",
                "    # Cache key\n",
                "    cache_key = f\"llm:{hashlib.md5(prompt.encode()).hexdigest()}\"\n",
                "    \n",
                "    # Check cache\n",
                "    if cache_key in cache:\n",
                "        print(f\"âœ… Cache HIT for: {prompt[:30]}...\")\n",
                "        return cache[cache_key]\n",
                "    \n",
                "    # Call LLM (simulated)\n",
                "    print(f\"ðŸ’° Cache MISS - calling LLM for: {prompt[:30]}...\")\n",
                "    time.sleep(0.5)  # Simulate latency\n",
                "    result = f\"Response to: {prompt}\"\n",
                "    \n",
                "    # Cache result\n",
                "    cache[cache_key] = result\n",
                "    return result\n\n",
                "# Test\n",
                "prompts = [\n",
                "    'What is LangGraph?',\n",
                "    'Explain agents',\n",
                "    'What is LangGraph?',  # Hit\n",
                "    'Explain agents'       # Hit\n",
                "]\n\n",
                "for prompt in prompts:\n",
                "    result = cached_llm_call(prompt)\n\n",
                "print(f'\\nðŸ“Š Cache: {len(cache)} entries')\n",
                "print('âœ… 50% cache hit rate - significant cost savings!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 3: Performance Profiling\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cProfile\n",
                "import pstats\n",
                "from io import StringIO\n\n",
                "def slow_function():\n",
                "    total = 0\n",
                "    for i in range(1000000):\n",
                "        total += i\n",
                "    return total\n\n",
                "def fast_function():\n",
                "    return sum(range(1000000))\n\n",
                "# Profile\n",
                "profiler = cProfile.Profile()\n",
                "profiler.enable()\n\n",
                "slow_result = slow_function()\n",
                "fast_result = fast_function()\n\n",
                "profiler.disable()\n\n",
                "# Print stats\n",
                "s = StringIO()\n",
                "ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n",
                "ps.print_stats(5)\n\n",
                "print(\"Top 5 time-consuming functions:\")\n",
                "print(s.getvalue()[:500])  # First 500 chars\n",
                "print('\\nâœ… Identify bottlenecks with profiling!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 4: Cost Tracking\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CostTracker:\n",
                "    def __init__(self):\n",
                "        self.total_tokens = 0\n",
                "        self.total_cost = 0\n",
                "        self.requests = 0\n",
                "        # GPT-4 pricing\n",
                "        self.cost_per_1k_tokens = 0.03\n",
                "    \n",
                "    def track(self, prompt_tokens: int, completion_tokens: int):\n",
                "        tokens = prompt_tokens + completion_tokens\n",
                "        cost = (tokens / 1000) * self.cost_per_1k_tokens\n",
                "        \n",
                "        self.total_tokens += tokens\n",
                "        self.total_cost += cost\n",
                "        self.requests += 1\n",
                "        return cost\n",
                "    \n",
                "    def report(self):\n",
                "        print(f\"ðŸ“Š Cost Report:\")\n",
                "        print(f\"  Requests: {self.requests}\")\n",
                "        print(f\"  Total tokens: {self.total_tokens:,}\")\n",
                "        print(f\"  Total cost: ${self.total_cost:.4f}\")\n",
                "        print(f\"  Avg cost/request: ${self.total_cost/max(1, self.requests):.4f}\")\n\n",
                "tracker = CostTracker()\n\n",
                "# Simulate requests\n",
                "requests = [\n",
                "    {'prompt': 500, 'completion': 200},\n",
                "    {'prompt': 300, 'completion': 150},\n",
                "    {'prompt': 1000, 'completion': 500}\n",
                "]\n\n",
                "for req in requests:\n",
                "    cost = tracker.track(req['prompt'], req['completion'])\n",
                "    print(f\"Request cost: ${cost:.4f}\")\n\n",
                "print()\n",
                "tracker.report()\n",
                "print('\\nâœ… Track costs to optimize spending!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example 5: Exponential Backoff\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n\n",
                "def exponential_backoff_retry(func, max_retries=3):\n",
                "    \"\"\"Retry with exponential backoff.\"\"\"\n",
                "    for attempt in range(max_retries):\n",
                "        try:\n",
                "            return func()\n",
                "        except Exception as e:\n",
                "            if attempt == max_retries - 1:\n",
                "                raise\n",
                "            \n",
                "            wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
                "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
                "            print(f\"Retrying in {wait_time:.2f}s...\")\n",
                "            time.sleep(wait_time)\n\n",
                "def unreliable_function():\n",
                "    if random.random() < 0.7:\n",
                "        raise Exception('Temporary error')\n",
                "    return 'Success!'\n\n",
                "# Test\n",
                "try:\n",
                "    result = exponential_backoff_retry(unreliable_function)\n",
                "    print(f\"âœ… {result}\")\n",
                "except Exception as e:\n",
                "    print(f\"âŒ Final failure: {e}\")\n\n",
                "print('âœ… Graceful error handling with backoff!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n\n",
                "You've run examples for:\n",
                "- âœ… Circuit breakers for resilience\n",
                "- âœ… Response caching for cost savings\n",
                "- âœ… Performance profiling\n",
                "- âœ… Cost tracking and reporting\n",
                "- âœ… Exponential backoff retry\n\n",
                "**Next:** `module-07-practice.ipynb` for optimization exercises!\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}