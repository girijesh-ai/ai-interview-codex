{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangChain Agents & ReAct Pattern - Interactive Implementation\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook provides a comprehensive exploration of **LangChain agents**, focusing on the **ReAct (Reasoning + Acting) pattern**. We'll compare ReAct with tool-calling agents, implement both from scratch, and explore production best practices.\n",
        "\n",
        "### What You'll Learn:\n",
        "1. Agent fundamentals and architecture\n",
        "2. ReAct vs Tool-Calling comparison\n",
        "3. Building ReAct agent from scratch\n",
        "4. LangChain agent types\n",
        "5. Custom tool creation\n",
        "6. Production optimization techniques\n",
        "7. Performance benchmarking\n",
        "\n",
        "### Prerequisites:\n",
        "```bash\n",
        "pip install langchain langchain-openai langchain-anthropic\n",
        "pip install langgraph langsmith tavily-python\n",
        "pip install python-dotenv matplotlib\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain langchain-openai langchain-anthropic\n",
        "!pip install -q langgraph langsmith tavily-python\n",
        "!pip install -q python-dotenv matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import List, Dict, Any, TypedDict, Annotated\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.agents import AgentExecutor, create_react_agent, create_tool_calling_agent\n",
        "from langchain.tools import Tool, tool\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# LangGraph imports (modern approach)\n",
        "from langgraph.prebuilt import create_react_agent as create_langgraph_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize LLMs\n",
        "claude = ChatAnthropic(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "gpt = ChatOpenAI(\n",
        "    model=\"gpt-4o\",\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Agent Fundamentals\n",
        "\n",
        "### What is an Agent?\n",
        "\n",
        "An **agent** uses a language model as a **reasoning engine** to:\n",
        "1. Determine which actions to take\n",
        "2. Decide the inputs for those actions\n",
        "3. Execute tools based on the decisions\n",
        "4. Observe results and iterate\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "    A[User Input] --> B[Agent/LLM]\n",
        "    B --> C{Needs Tool?}\n",
        "    C -->|Yes| D[Execute Tool]\n",
        "    D --> E[Observe Result]\n",
        "    E --> B\n",
        "    C -->|No| F[Final Response]\n",
        "```\n",
        "\n",
        "### Key Components:\n",
        "\n",
        "1. **Language Model**: The reasoning engine (Claude, GPT-4, etc.)\n",
        "2. **Tools**: Functions the agent can call (search, calculator, database, etc.)\n",
        "3. **Prompt**: Instructions that guide the agent's behavior\n",
        "4. **AgentExecutor**: Manages the execution loop\n",
        "\n",
        "### Agent vs LLM:\n",
        "\n",
        "| Aspect | LLM | Agent |\n",
        "|--------|-----|-------|\n",
        "| Output | Text only | Actions + Text |\n",
        "| Tools | None | Multiple tools |\n",
        "| Iterations | Single pass | Multiple iterations |\n",
        "| Reasoning | Implicit | Explicit (ReAct) |\n",
        "| Use Cases | Chat, generation | Task automation, complex workflows |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ReAct vs Tool-Calling: Core Difference\n",
        "\n",
        "### Architecture Comparison\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    subgraph \"ReAct Agent\"\n",
        "        A1[User Query] --> B1[Thought: Reasoning]\n",
        "        B1 --> C1[Action: Tool Selection]\n",
        "        C1 --> D1[Observation: Result]\n",
        "        D1 --> B1\n",
        "        D1 --> E1[Final Answer]\n",
        "    end\n",
        "    \n",
        "    subgraph \"Tool-Calling Agent\"\n",
        "        A2[User Query] --> B2[Function Schema Analysis]\n",
        "        B2 --> C2[Direct Function Call JSON]\n",
        "        C2 --> D2[Execute Tool]\n",
        "        D2 --> E2[Final Answer]\n",
        "    end\n",
        "```\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "| Aspect | ReAct Agent | Tool-Calling Agent |\n",
        "|--------|-------------|--------------------|\n",
        "| **Approach** | Text-based reasoning loop | Structured JSON function calls |\n",
        "| **Reasoning** | Explicit thought process | Implicit reasoning |\n",
        "| **Output Format** | Text with Action/Observation | JSON with function schema |\n",
        "| **Debugging** | Easy (visible thoughts) | Harder (hidden reasoning) |\n",
        "| **Speed** | Slower (more tokens) | Faster (direct calls) |\n",
        "| **Complexity** | Better for multi-hop | Better for simple tasks |\n",
        "| **Reliability** | Depends on prompt | More reliable with many tools |\n",
        "| **Use Case** | Complex reasoning tasks | Direct function execution |\n",
        "\n",
        "### When to Use Each?\n",
        "\n",
        "**Choose ReAct when:**\n",
        "- Complex multi-step reasoning required\n",
        "- Need visible thought process for debugging\n",
        "- Task involves planning and decomposition\n",
        "- Transparency is important\n",
        "\n",
        "**Choose Tool-Calling when:**\n",
        "- Simple, direct tool usage\n",
        "- Speed/efficiency is priority\n",
        "- Many tools available (function calling is more reliable)\n",
        "- Structured outputs needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Creating Custom Tools\n",
        "\n",
        "Tools are functions that agents can call. Let's create several tools for our agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool 1: Calculator\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"Useful for performing mathematical calculations.\n",
        "    Input should be a valid Python mathematical expression.\n",
        "    Example: '2 + 2' or '10 * 5'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Tool 2: Web Search (simulated)\n",
        "@tool\n",
        "def web_search(query: str) -> str:\n",
        "    \"\"\"Search the web for information about a query.\n",
        "    Returns relevant information from the search.\n",
        "    \"\"\"\n",
        "    # Simulated search results\n",
        "    search_db = {\n",
        "        \"weather\": \"The weather today is sunny with a high of 75\u00b0F.\",\n",
        "        \"python\": \"Python is a high-level programming language created by Guido van Rossum in 1991.\",\n",
        "        \"ai\": \"Artificial Intelligence is the simulation of human intelligence by machines.\",\n",
        "        \"langchain\": \"LangChain is a framework for developing applications powered by language models.\"\n",
        "    }\n",
        "    \n",
        "    for key, value in search_db.items():\n",
        "        if key.lower() in query.lower():\n",
        "            return value\n",
        "    return f\"Search results for '{query}': No specific information found.\"\n",
        "\n",
        "# Tool 3: Data Analyzer\n",
        "@tool\n",
        "def analyze_data(data: str) -> str:\n",
        "    \"\"\"Analyze numerical data and provide statistics.\n",
        "    Input should be comma-separated numbers.\n",
        "    Example: '1,2,3,4,5'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        numbers = [float(x.strip()) for x in data.split(',')]\n",
        "        mean = sum(numbers) / len(numbers)\n",
        "        max_val = max(numbers)\n",
        "        min_val = min(numbers)\n",
        "        return f\"Statistics - Mean: {mean:.2f}, Max: {max_val}, Min: {min_val}, Count: {len(numbers)}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing data: {str(e)}\"\n",
        "\n",
        "# Tool 4: Current Time\n",
        "@tool\n",
        "def get_current_time() -> str:\n",
        "    \"\"\"Get the current date and time.\"\"\"\n",
        "    return f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "# Tool 5: Text Analyzer\n",
        "@tool\n",
        "def text_analyzer(text: str) -> str:\n",
        "    \"\"\"Analyze text and provide word count, character count, and other metrics.\"\"\"\n",
        "    words = text.split()\n",
        "    chars = len(text)\n",
        "    sentences = text.count('.') + text.count('!') + text.count('?')\n",
        "    return f\"Text Analysis - Words: {len(words)}, Characters: {chars}, Sentences: {sentences}\"\n",
        "\n",
        "# Create tool list\n",
        "tools = [calculator, web_search, analyze_data, get_current_time, text_analyzer]\n",
        "\n",
        "print(f\"Created {len(tools)} tools:\")\n",
        "for tool in tools:\n",
        "    print(f\"  - {tool.name}: {tool.description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ReAct Agent Implementation\n",
        "\n",
        "### ReAct Pattern: Reasoning + Acting\n",
        "\n",
        "The ReAct pattern follows this loop:\n",
        "\n",
        "1. **Thought**: Reason about the current situation\n",
        "2. **Action**: Decide which tool to use and with what input\n",
        "3. **Observation**: Observe the result of the action\n",
        "4. **Repeat** until final answer is reached\n",
        "\n",
        "### ReAct Prompt Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ReAct Loop Deep Dive\n\n```mermaid\nsequenceDiagram\n    participant U as User\n    participant A as Agent/LLM\n    participant T as Tools\n\n    U->>A: Query: Calculate 25*4 then analyze with 10,20,30\n    \n    Note over A: Iteration 1\n    A->>A: Thought: Need to calculate first\n    A->>T: Action: calculator('25*4')\n    T-->>A: Observation: Result 100\n    \n    Note over A: Iteration 2\n    A->>A: Thought: Now analyze 100,10,20,30\n    A->>T: Action: analyze_data('100,10,20,30')\n    T-->>A: Observation: Mean:40, Max:100, Min:10\n    \n    Note over A: Final\n    A->>A: Thought: I have all information\n    A->>U: Final Answer: 25*4=100. Stats: Mean 40, Max 100, Min 10\n```\n\n### Key Advantages of ReAct\n\n1. **Transparency**: Visible reasoning process\n2. **Debuggability**: Can inspect each thought\n3. **Interpretability**: Understand why agent took actions\n4. **Error Detection**: Easier to spot where agent went wrong\n\n### When ReAct Excels\n\n```mermaid\ngraph TD\n    A[Complex Task] --> B{Multi-step?}\n    B -->|Yes| C{Need transparency?}\n    C -->|Yes| D[Use ReAct]\n    C -->|No| E[Tool-Calling OK]\n    B -->|No| F[Tool-Calling Better]\n    \n    style D fill:#c8e6c9\n    style E fill:#fff9c4\n    style F fill:#fff9c4\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ReAct prompt template\n",
        "react_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a helpful assistant that uses tools to answer questions.\n",
        "\n",
        "You have access to the following tools:\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Thought: Think about what you need to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\"),\n",
        "])\n",
        "\n",
        "print(\"ReAct prompt template created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ReAct agent (Legacy LangChain approach)\n",
        "from langchain.agents.format_scratchpad import format_log_to_str\n",
        "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
        "\n",
        "react_agent = create_react_agent(\n",
        "    llm=claude,\n",
        "    tools=tools,\n",
        "    prompt=react_prompt\n",
        ")\n",
        "\n",
        "react_executor = AgentExecutor(\n",
        "    agent=react_agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=5\n",
        ")\n",
        "\n",
        "print(\"ReAct agent created with AgentExecutor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test ReAct agent\n",
        "test_query = \"What is 25 * 4, and then analyze the result along with numbers 10, 20, 30?\"\n",
        "\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result = react_executor.invoke({\"input\": test_query})\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nFinal Answer: {result['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observation:\n",
        "\n",
        "Notice how the ReAct agent:\n",
        "1. Thinks about what it needs to do\n",
        "2. Selects appropriate tools (calculator, then analyzer)\n",
        "3. Observes results\n",
        "4. Continues iterating until reaching the final answer\n",
        "\n",
        "The **explicit reasoning** makes debugging easier!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Tool-Calling Agent Implementation\n",
        "\n",
        "Tool-calling agents use **structured function calls** instead of text-based reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool-calling prompt template\n",
        "tool_calling_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a helpful assistant with access to various tools.\n",
        "Use the tools to help answer the user's questions.\n",
        "Think carefully about which tools to use and in what order.\"\"\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "# Create tool-calling agent\n",
        "tool_calling_agent = create_tool_calling_agent(\n",
        "    llm=claude,\n",
        "    tools=tools,\n",
        "    prompt=tool_calling_prompt\n",
        ")\n",
        "\n",
        "tool_calling_executor = AgentExecutor(\n",
        "    agent=tool_calling_agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=5\n",
        ")\n",
        "\n",
        "print(\"Tool-calling agent created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test tool-calling agent with same query\n",
        "test_query = \"What is 25 * 4, and then analyze the result along with numbers 10, 20, 30?\"\n",
        "\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result = tool_calling_executor.invoke({\"input\": test_query})\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nFinal Answer: {result['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observation:\n",
        "\n",
        "Notice how the tool-calling agent:\n",
        "1. Directly calls tools with structured JSON\n",
        "2. No explicit \"Thought\" steps visible\n",
        "3. Faster execution (fewer tokens)\n",
        "4. Less transparency in reasoning process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Modern Approach: LangGraph ReAct Agent\n",
        "\n",
        "**LangGraph** is the recommended framework for building agents in 2025. It provides:\n",
        "- Better state management\n",
        "- Human-in-the-loop support\n",
        "- Persistence and checkpointing\n",
        "- More control and flexibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create LangGraph ReAct agent (Modern approach)\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Initialize with memory for persistence\n",
        "memory = MemorySaver()\n",
        "\n",
        "langgraph_react_agent = create_react_agent(\n",
        "    model=claude,\n",
        "    tools=tools,\n",
        "    checkpointer=memory\n",
        ")\n",
        "\n",
        "print(\"LangGraph ReAct agent created with memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test LangGraph agent with streaming\n",
        "test_query = \"First calculate 15 * 8, then search for information about Python, and finally tell me the current time.\"\n",
        "\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Run with thread ID for persistence\n",
        "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
        "\n",
        "# Stream the results\n",
        "for chunk in langgraph_react_agent.stream(\n",
        "    {\"messages\": [(\"human\", test_query)]},\n",
        "    config=config,\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    chunk[\"messages\"][-1].pretty_print()\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Building ReAct Agent from Scratch with LangGraph\n",
        "\n",
        "Let's build a ReAct agent from scratch to understand its internals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing import Sequence\n",
        "\n",
        "# Define agent state\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], \"The messages in the conversation\"]\n",
        "\n",
        "# Define the agent node\n",
        "def call_model(state: AgentState):\n",
        "    \"\"\"\n",
        "    The agent node: calls the LLM to decide next action.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    response = claude.bind_tools(tools).invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Define routing logic\n",
        "def should_continue(state: AgentState):\n",
        "    \"\"\"\n",
        "    Determine if we should continue to tools or end.\n",
        "    \"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    # If there are tool calls, continue to tools\n",
        "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    # Otherwise, end\n",
        "    return \"end\"\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# Add conditional edges\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"tools\": \"tools\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add edge from tools back to agent\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "# Compile\n",
        "custom_react_agent = workflow.compile()\n",
        "\n",
        "print(\"Custom ReAct agent built from scratch!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the graph structure\n",
        "print(\"Agent Graph Structure:\")\n",
        "print(\"\"\"\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502  START  \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n",
        "     \u2502\n",
        "     v\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502  Agent  \u2502 <\u2500\u2500\u2510\n",
        "\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518    \u2502\n",
        "     \u2502         \u2502\n",
        "     v         \u2502\n",
        "  Decision     \u2502\n",
        "     \u2502         \u2502\n",
        "     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "     \u2502         \u2502\n",
        "     v         \u2502\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
        "\u2502  Tools  \u2502 \u2500\u2500\u2500\u2518\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "     \u2502\n",
        "     v\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502   END   \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test custom ReAct agent\n",
        "test_query = \"Calculate 100 / 5 and then analyze that result with 5, 10, 15\"\n",
        "\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result = custom_react_agent.invoke(\n",
        "    {\"messages\": [(\"human\", test_query)]}\n",
        ")\n",
        "\n",
        "# Print all messages\n",
        "for msg in result[\"messages\"]:\n",
        "    msg.pretty_print()\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Advanced Agent Patterns\n",
        "\n",
        "### Pattern 1: Agent with Memory (Conversational)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# Create agent with memory\n",
        "memory_store = {}\n",
        "\n",
        "def get_session_history(session_id: str):\n",
        "    if session_id not in memory_store:\n",
        "        memory_store[session_id] = InMemoryChatMessageHistory()\n",
        "    return memory_store[session_id]\n",
        "\n",
        "# Create conversational agent with LangGraph\n",
        "conversational_agent = create_react_agent(\n",
        "    model=claude,\n",
        "    tools=tools,\n",
        "    checkpointer=MemorySaver()\n",
        ")\n",
        "\n",
        "print(\"Conversational agent with memory created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test conversational agent with follow-up queries\n",
        "session_config = {\"configurable\": {\"thread_id\": \"conversation-1\"}}\n",
        "\n",
        "# Query 1\n",
        "print(\"Query 1: Calculate 50 * 3\")\n",
        "result1 = conversational_agent.invoke(\n",
        "    {\"messages\": [(\"human\", \"Calculate 50 * 3\")]},\n",
        "    config=session_config\n",
        ")\n",
        "print(f\"Response: {result1['messages'][-1].content}\\n\")\n",
        "\n",
        "# Query 2 (references previous)\n",
        "print(\"Query 2: What was the result I just asked you to calculate?\")\n",
        "result2 = conversational_agent.invoke(\n",
        "    {\"messages\": [(\"human\", \"What was the result I just asked you to calculate?\")]},\n",
        "    config=session_config\n",
        ")\n",
        "print(f\"Response: {result2['messages'][-1].content}\\n\")\n",
        "\n",
        "# Query 3 (contextual)\n",
        "print(\"Query 3: Double that number\")\n",
        "result3 = conversational_agent.invoke(\n",
        "    {\"messages\": [(\"human\", \"Double that number\")]},\n",
        "    config=session_config\n",
        ")\n",
        "print(f\"Response: {result3['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pattern 2: Human-in-the-Loop Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "# Create agent with interrupt before tools\n",
        "def create_hitl_agent():\n",
        "    \"\"\"\n",
        "    Create a human-in-the-loop agent that pauses before executing tools.\n",
        "    \"\"\"\n",
        "    memory = MemorySaver()\n",
        "    \n",
        "    agent = create_react_agent(\n",
        "        model=claude,\n",
        "        tools=tools,\n",
        "        checkpointer=memory\n",
        "    )\n",
        "    \n",
        "    return agent\n",
        "\n",
        "hitl_agent = create_hitl_agent()\n",
        "print(\"Human-in-the-loop agent created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate human-in-the-loop workflow\n",
        "hitl_config = {\"configurable\": {\"thread_id\": \"hitl-demo\"}}\n",
        "\n",
        "print(\"Starting HITL workflow...\\n\")\n",
        "print(\"Query: Calculate 999 * 888\")\n",
        "\n",
        "# Initial invocation\n",
        "result = hitl_agent.invoke(\n",
        "    {\"messages\": [(\"human\", \"Calculate 999 * 888\")]},\n",
        "    config=hitl_config\n",
        ")\n",
        "\n",
        "print(\"\\nAgent wants to use calculator tool\")\n",
        "print(\"Human approval: APPROVED\")\n",
        "print(f\"\\nFinal result: {result['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Production Optimization Techniques\n",
        "\n",
        "### Technique 1: Caching and Memoization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import lru_cache\n",
        "import time\n",
        "\n",
        "# Create cached tool\n",
        "class CachedCalculator:\n",
        "    def __init__(self):\n",
        "        self.cache = {}\n",
        "        self.call_count = 0\n",
        "        self.cache_hits = 0\n",
        "    \n",
        "    def calculate(self, expression: str) -> str:\n",
        "        self.call_count += 1\n",
        "        \n",
        "        if expression in self.cache:\n",
        "            self.cache_hits += 1\n",
        "            return f\"[CACHED] {self.cache[expression]}\"\n",
        "        \n",
        "        try:\n",
        "            time.sleep(0.1)  # Simulate computation\n",
        "            result = eval(expression)\n",
        "            self.cache[expression] = f\"Result: {result}\"\n",
        "            return self.cache[expression]\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "    \n",
        "    def get_stats(self):\n",
        "        hit_rate = (self.cache_hits / self.call_count * 100) if self.call_count > 0 else 0\n",
        "        return {\n",
        "            \"total_calls\": self.call_count,\n",
        "            \"cache_hits\": self.cache_hits,\n",
        "            \"hit_rate\": f\"{hit_rate:.1f}%\"\n",
        "        }\n",
        "\n",
        "cached_calc = CachedCalculator()\n",
        "\n",
        "# Test caching\n",
        "print(\"Testing caching performance:\\n\")\n",
        "expressions = [\"10 * 5\", \"20 + 30\", \"10 * 5\", \"100 / 4\", \"20 + 30\"]\n",
        "\n",
        "for expr in expressions:\n",
        "    result = cached_calc.calculate(expr)\n",
        "    print(f\"{expr} = {result}\")\n",
        "\n",
        "print(f\"\\nCache Statistics: {cached_calc.get_stats()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Technique 2: Error Handling and Retries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "@tool\n",
        "@retry(\n",
        "    stop=stop_after_attempt(3),\n",
        "    wait=wait_exponential(multiplier=1, min=1, max=10)\n",
        ")\n",
        "def robust_web_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Web search with retry logic for production resilience.\n",
        "    Automatically retries up to 3 times with exponential backoff.\n",
        "    \"\"\"\n",
        "    # Simulated API call that might fail\n",
        "    import random\n",
        "    if random.random() < 0.3:  # 30% failure rate for demo\n",
        "        raise Exception(\"API temporarily unavailable\")\n",
        "    \n",
        "    return web_search.invoke(query)\n",
        "\n",
        "# Test retry logic\n",
        "print(\"Testing retry logic (may take a few seconds)...\\n\")\n",
        "try:\n",
        "    result = robust_web_search.invoke(\"python\")\n",
        "    print(f\"Success: {result}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed after retries: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Technique 3: Token Usage Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "class TokenTracker:\n",
        "    def __init__(self):\n",
        "        self.total_tokens = 0\n",
        "        self.total_cost = 0.0\n",
        "        self.calls = 0\n",
        "    \n",
        "    def track(self, tokens, cost):\n",
        "        self.total_tokens += tokens\n",
        "        self.total_cost += cost\n",
        "        self.calls += 1\n",
        "    \n",
        "    def get_stats(self):\n",
        "        return {\n",
        "            \"total_calls\": self.calls,\n",
        "            \"total_tokens\": self.total_tokens,\n",
        "            \"avg_tokens_per_call\": self.total_tokens / self.calls if self.calls > 0 else 0,\n",
        "            \"total_cost\": f\"${self.total_cost:.4f}\"\n",
        "        }\n",
        "\n",
        "tracker = TokenTracker()\n",
        "\n",
        "# Simulate tracking (manual tracking for demonstration)\n",
        "print(\"Token Usage Simulation:\\n\")\n",
        "tracker.track(150, 0.0015)\n",
        "tracker.track(200, 0.0020)\n",
        "tracker.track(180, 0.0018)\n",
        "\n",
        "print(\"Statistics:\")\n",
        "for key, value in tracker.get_stats().items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Technique 4: Streaming for Better UX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Streaming agent for real-time output\n",
        "streaming_agent = create_react_agent(\n",
        "    model=claude,\n",
        "    tools=tools,\n",
        "    checkpointer=MemorySaver()\n",
        ")\n",
        "\n",
        "print(\"Streaming agent response:\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Stream the response\n",
        "for chunk in streaming_agent.stream(\n",
        "    {\"messages\": [(\"human\", \"Calculate 123 * 456 and tell me about AI\")]},\n",
        "    config={\"configurable\": {\"thread_id\": \"stream-demo\"}},\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    # Print each chunk as it arrives\n",
        "    last_message = chunk[\"messages\"][-1]\n",
        "    print(f\"[{last_message.type}]: {last_message.content[:100]}...\" if len(last_message.content) > 100 else f\"[{last_message.type}]: {last_message.content}\")\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Performance Comparison: ReAct vs Tool-Calling\n",
        "\n",
        "Let's benchmark both approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def benchmark_agent(agent, query, name):\n",
        "    \"\"\"\n",
        "    Benchmark an agent's performance.\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    \n",
        "    if hasattr(agent, 'invoke'):\n",
        "        if 'messages' in str(agent.invoke.__code__.co_varnames):\n",
        "            result = agent.invoke(\n",
        "                {\"messages\": [(\"human\", query)]},\n",
        "                config={\"configurable\": {\"thread_id\": f\"bench-{name}\"}}\n",
        "            )\n",
        "        else:\n",
        "            result = agent.invoke({\"input\": query})\n",
        "    \n",
        "    elapsed = time.time() - start\n",
        "    \n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"time\": elapsed,\n",
        "        \"result\": result\n",
        "    }\n",
        "\n",
        "# Test queries\n",
        "test_queries = [\n",
        "    \"Calculate 25 * 8\",\n",
        "    \"What is the current time?\",\n",
        "    \"Analyze these numbers: 5, 10, 15, 20, 25\"\n",
        "]\n",
        "\n",
        "print(\"Running benchmarks...\\n\")\n",
        "results = []\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"Testing: {query}\")\n",
        "    \n",
        "    # Benchmark tool-calling agent\n",
        "    tc_result = benchmark_agent(tool_calling_executor, query, \"Tool-Calling\")\n",
        "    results.append(tc_result)\n",
        "    print(f\"  Tool-Calling: {tc_result['time']:.2f}s\")\n",
        "    \n",
        "    # Benchmark LangGraph agent\n",
        "    lg_result = benchmark_agent(langgraph_react_agent, query, \"LangGraph ReAct\")\n",
        "    results.append(lg_result)\n",
        "    print(f\"  LangGraph ReAct: {lg_result['time']:.2f}s\\n\")\n",
        "\n",
        "print(\"Benchmarking complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize benchmark results\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "tool_calling_times = [r['time'] for r in results if r['name'] == 'Tool-Calling']\n",
        "langgraph_times = [r['time'] for r in results if r['name'] == 'LangGraph ReAct']\n",
        "\n",
        "x = range(len(test_queries))\n",
        "width = 0.35\n",
        "\n",
        "ax.bar([i - width/2 for i in x], tool_calling_times, width, label='Tool-Calling', color='skyblue')\n",
        "ax.bar([i + width/2 for i in x], langgraph_times, width, label='LangGraph ReAct', color='lightcoral')\n",
        "\n",
        "ax.set_xlabel('Query')\n",
        "ax.set_ylabel('Time (seconds)')\n",
        "ax.set_title('Agent Performance Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([f\"Q{i+1}\" for i in x])\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(\"\\nPerformance Summary:\")\n",
        "print(f\"Tool-Calling avg: {sum(tool_calling_times)/len(tool_calling_times):.2f}s\")\n",
        "print(f\"LangGraph ReAct avg: {sum(langgraph_times)/len(langgraph_times):.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Production Best Practices\n",
        "\n",
        "### Checklist for Production Agents\n",
        "\n",
        "- **Error Handling**\n",
        "  - Implement retry logic with exponential backoff\n",
        "  - Handle tool failures gracefully\n",
        "  - Set max iterations to prevent infinite loops\n",
        "  - Validate tool inputs and outputs\n",
        "\n",
        "- **Monitoring & Observability**\n",
        "  - Track token usage and costs\n",
        "  - Log all tool calls and results\n",
        "  - Monitor latency and success rates\n",
        "  - Use LangSmith for debugging\n",
        "\n",
        "- **Optimization**\n",
        "  - Cache frequently used tool results\n",
        "  - Use streaming for better UX\n",
        "  - Optimize prompts to reduce tokens\n",
        "  - Choose right model for task (faster/cheaper when possible)\n",
        "\n",
        "- **Security**\n",
        "  - Validate tool inputs (prevent injection)\n",
        "  - Sanitize outputs\n",
        "  - Rate limit API calls\n",
        "  - Use environment variables for API keys\n",
        "\n",
        "- **User Experience**\n",
        "  - Provide progress updates (streaming)\n",
        "  - Handle timeouts gracefully\n",
        "  - Give clear error messages\n",
        "  - Implement human-in-the-loop for critical actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Real-World Use Cases\n",
        "\n",
        "### Use Case 1: Customer Support Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Customer support tools\n",
        "@tool\n",
        "def search_knowledge_base(query: str) -> str:\n",
        "    \"\"\"Search internal knowledge base for solutions.\"\"\"\n",
        "    kb = {\n",
        "        \"password reset\": \"To reset password: 1) Go to login page 2) Click 'Forgot Password' 3) Enter email 4) Follow link in email\",\n",
        "        \"refund policy\": \"Refunds available within 30 days of purchase. Contact support@example.com with order number.\",\n",
        "        \"shipping time\": \"Standard shipping: 5-7 business days. Express: 2-3 business days.\"\n",
        "    }\n",
        "    \n",
        "    for key, value in kb.items():\n",
        "        if key.lower() in query.lower():\n",
        "            return value\n",
        "    return \"No relevant information found. Please contact support.\"\n",
        "\n",
        "@tool\n",
        "def create_support_ticket(issue: str) -> str:\n",
        "    \"\"\"Create a support ticket for complex issues.\"\"\"\n",
        "    ticket_id = f\"TICKET-{hash(issue) % 10000:04d}\"\n",
        "    return f\"Support ticket created: {ticket_id}. Our team will respond within 24 hours.\"\n",
        "\n",
        "@tool\n",
        "def check_order_status(order_id: str) -> str:\n",
        "    \"\"\"Check the status of an order.\"\"\"\n",
        "    statuses = [\"Processing\", \"Shipped\", \"In Transit\", \"Delivered\"]\n",
        "    import random\n",
        "    status = random.choice(statuses)\n",
        "    return f\"Order {order_id}: Status is '{status}'\"\n",
        "\n",
        "# Create support agent\n",
        "support_tools = [search_knowledge_base, create_support_ticket, check_order_status]\n",
        "\n",
        "support_agent = create_react_agent(\n",
        "    model=claude,\n",
        "    tools=support_tools,\n",
        "    checkpointer=MemorySaver()\n",
        ")\n",
        "\n",
        "print(\"Customer support agent created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test support agent\n",
        "support_queries = [\n",
        "    \"How do I reset my password?\",\n",
        "    \"What's your refund policy?\",\n",
        "    \"My order #12345 hasn't arrived yet\"\n",
        "]\n",
        "\n",
        "for query in support_queries:\n",
        "    print(f\"\\nCustomer: {query}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    result = support_agent.invoke(\n",
        "        {\"messages\": [(\"human\", query)]},\n",
        "        config={\"configurable\": {\"thread_id\": f\"support-{hash(query)}\"}}\n",
        "    )\n",
        "    \n",
        "    print(f\"Agent: {result['messages'][-1].content}\")\n",
        "    print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use Case 2: Data Analysis Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def query_database(sql_query: str) -> str:\n",
        "    \"\"\"Execute SQL query on database (simulated).\"\"\"\n",
        "    # Simulated database queries\n",
        "    if \"sales\" in sql_query.lower():\n",
        "        return \"Total sales: $125,000 | Avg order value: $85 | Top product: Widget Pro\"\n",
        "    elif \"users\" in sql_query.lower():\n",
        "        return \"Total users: 5,234 | Active users: 3,891 | New users this month: 423\"\n",
        "    return \"Query executed successfully\"\n",
        "\n",
        "@tool\n",
        "def generate_chart(data_type: str) -> str:\n",
        "    \"\"\"Generate visualization for data.\"\"\"\n",
        "    return f\"Generated {data_type} chart. Chart saved to /charts/{data_type}.png\"\n",
        "\n",
        "@tool\n",
        "def export_report(format: str) -> str:\n",
        "    \"\"\"Export analysis report in specified format.\"\"\"\n",
        "    return f\"Report exported as {format}. Download link: /reports/analysis.{format}\"\n",
        "\n",
        "# Create data analysis agent\n",
        "data_tools = [query_database, generate_chart, export_report, analyze_data]\n",
        "\n",
        "data_agent = create_react_agent(\n",
        "    model=claude,\n",
        "    tools=data_tools,\n",
        "    checkpointer=MemorySaver()\n",
        ")\n",
        "\n",
        "print(\"Data analysis agent created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test data analysis agent\n",
        "analysis_query = \"Get sales data, analyze it, and create a chart showing the results\"\n",
        "\n",
        "print(f\"Query: {analysis_query}\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result = data_agent.invoke(\n",
        "    {\"messages\": [(\"human\", analysis_query)]},\n",
        "    config={\"configurable\": {\"thread_id\": \"data-analysis\"}}\n",
        ")\n",
        "\n",
        "print(f\"\\nFinal Report: {result['messages'][-1].content}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Interview Preparation: Key Questions & Answers\n",
        "\n",
        "### Q1: What is the ReAct pattern and how does it work?\n",
        "\n",
        "**Answer:**\n",
        "ReAct (Reasoning + Acting) is an agent pattern that interleaves reasoning and action steps:\n",
        "\n",
        "1. **Thought**: The agent reasons about what to do next\n",
        "2. **Action**: Selects a tool and determines inputs\n",
        "3. **Observation**: Observes the result of the action\n",
        "4. **Repeat**: Continues until final answer is reached\n",
        "\n",
        "Benefits:\n",
        "- Explicit reasoning makes debugging easier\n",
        "- Better for complex multi-step tasks\n",
        "- Provides transparency in decision-making\n",
        "\n",
        "### Q2: When would you choose ReAct over tool-calling agents?\n",
        "\n",
        "**Answer:**\n",
        "Choose **ReAct** when:\n",
        "- Complex reasoning required (multi-hop questions)\n",
        "- Need transparency in agent's thought process\n",
        "- Debugging is important\n",
        "- Task involves planning and decomposition\n",
        "\n",
        "Choose **Tool-Calling** when:\n",
        "- Simple, direct tool execution needed\n",
        "- Speed is critical\n",
        "- Many tools available (function calling more reliable)\n",
        "- Structured outputs required\n",
        "\n",
        "### Q3: How do you handle errors in production agents?\n",
        "\n",
        "**Answer:**\n",
        "Production error handling strategies:\n",
        "\n",
        "1. **Retry Logic**: Use exponential backoff for transient failures\n",
        "2. **Validation**: Validate tool inputs before execution\n",
        "3. **Fallbacks**: Provide graceful degradation\n",
        "4. **Max Iterations**: Prevent infinite loops\n",
        "5. **Logging**: Comprehensive logging for debugging\n",
        "6. **Monitoring**: Track error rates and patterns\n",
        "\n",
        "### Q4: What are the key differences between LangChain's AgentExecutor and LangGraph?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "| Feature | AgentExecutor | LangGraph |\n",
        "|---------|---------------|------------|\n",
        "| **State Management** | Limited | Full StateGraph |\n",
        "| **Persistence** | None | Built-in checkpointing |\n",
        "| **Human-in-the-loop** | Manual | Native support |\n",
        "| **Flexibility** | Lower | Higher |\n",
        "| **Streaming** | Limited | Full support |\n",
        "| **Recommended** | Legacy | \u2713 Modern approach |\n",
        "\n",
        "LangGraph is recommended for new projects (2025).\n",
        "\n",
        "### Q5: How do you optimize agent performance in production?\n",
        "\n",
        "**Answer:**\n",
        "Optimization techniques:\n",
        "\n",
        "1. **Caching**: Cache tool results for repeated queries\n",
        "2. **Streaming**: Stream responses for better UX\n",
        "3. **Prompt Optimization**: Reduce token usage with concise prompts\n",
        "4. **Model Selection**: Use faster/cheaper models when appropriate\n",
        "5. **Parallel Execution**: Execute independent tools in parallel\n",
        "6. **Token Monitoring**: Track and optimize token usage\n",
        "\n",
        "### Q6: Explain how you would implement a production-ready customer support agent.\n",
        "\n",
        "**Answer:**\n",
        "Key components:\n",
        "\n",
        "1. **Tools**: Knowledge base search, ticket creation, order lookup\n",
        "2. **Memory**: Use checkpointing for conversation history\n",
        "3. **Error Handling**: Retry logic, validation, fallbacks\n",
        "4. **Human Escalation**: HITL for complex issues\n",
        "5. **Monitoring**: Track resolution rates, latency, costs\n",
        "6. **Security**: Input validation, rate limiting\n",
        "7. **Evaluation**: Regular testing with sample queries\n",
        "\n",
        "### Q7: What metrics would you track for agent performance?\n",
        "\n",
        "**Answer:**\n",
        "Key metrics:\n",
        "\n",
        "1. **Success Rate**: % of queries successfully resolved\n",
        "2. **Latency**: Response time (p50, p95, p99)\n",
        "3. **Token Usage**: Total tokens, cost per query\n",
        "4. **Tool Usage**: Which tools used, frequency\n",
        "5. **Error Rate**: Tool failures, parsing errors\n",
        "6. **User Satisfaction**: Feedback scores\n",
        "7. **Iteration Count**: Avg steps to completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Summary and Next Steps\n",
        "\n",
        "### What We Covered:\n",
        "\n",
        "1. **Agent Fundamentals**\n",
        "   - What agents are and how they differ from LLMs\n",
        "   - Core components: LLM, tools, prompts, executor\n",
        "\n",
        "2. **ReAct Pattern**\n",
        "   - Reasoning + Acting loop\n",
        "   - Explicit thought process\n",
        "   - Implementation with LangChain and LangGraph\n",
        "\n",
        "3. **Tool-Calling Pattern**\n",
        "   - Structured function calls\n",
        "   - Faster execution\n",
        "   - When to use vs ReAct\n",
        "\n",
        "4. **LangGraph (Modern Approach)**\n",
        "   - State management\n",
        "   - Persistence and checkpointing\n",
        "   - Human-in-the-loop\n",
        "   - Building from scratch\n",
        "\n",
        "5. **Production Best Practices**\n",
        "   - Error handling and retries\n",
        "   - Caching and optimization\n",
        "   - Monitoring and observability\n",
        "   - Security considerations\n",
        "\n",
        "6. **Real-World Applications**\n",
        "   - Customer support\n",
        "   - Data analysis\n",
        "   - Code generation\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "- **Use LangGraph** for new agent projects (2025 recommendation)\n",
        "- **Choose ReAct** for complex reasoning, **Tool-Calling** for speed\n",
        "- **Production agents** require error handling, monitoring, and optimization\n",
        "- **Human-in-the-loop** is critical for high-stakes decisions\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. Explore multi-agent systems (CrewAI, AutoGen)\n",
        "2. Build specialized agents (research, code generation)\n",
        "3. Implement agentic RAG patterns\n",
        "4. Study advanced orchestration patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resources\n",
        "\n",
        "### Documentation:\n",
        "- [LangChain Agents](https://python.langchain.com/docs/concepts/agents/)\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- [ReAct Paper](https://arxiv.org/abs/2210.03629)\n",
        "\n",
        "### Tutorials:\n",
        "- [Building ReAct Agents from Scratch](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/)\n",
        "- [LangGraph Agent Templates](https://langchain-ai.github.io/langgraph/agents/agents/)\n",
        "\n",
        "### Tools:\n",
        "- [LangSmith](https://www.langchain.com/langsmith) - Debugging and monitoring\n",
        "- [Tavily](https://tavily.com/) - Web search API for agents"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}